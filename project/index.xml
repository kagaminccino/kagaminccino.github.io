<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Shang-Yi Chuang</title>
    <link>https://kagaminccino.github.io/project/</link>
      <atom:link href="https://kagaminccino.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 04 May 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://kagaminccino.github.io/media/icon_hu97fe3e40591f4d3389a975f0ec5a9dc7_247274_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://kagaminccino.github.io/project/</link>
    </image>
    
    <item>
      <title>DTS Stock Tracking</title>
      <link>https://kagaminccino.github.io/project/dts/</link>
      <pubDate>Wed, 04 May 2022 00:00:00 +0000</pubDate>
      <guid>https://kagaminccino.github.io/project/dts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Going Everywhere</title>
      <link>https://kagaminccino.github.io/project/goingeverywhere/</link>
      <pubDate>Mon, 25 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://kagaminccino.github.io/project/goingeverywhere/</guid>
      <description>&lt;p&gt;The story starts from being a foreigner. I have been living abroad for a long time. When moving to a new environment, the lack of the sense of feeling belonging and human rights makes me feel like an outsider or even invisible.&lt;/p&gt;
&lt;p&gt;After living in many places, I have learned how to get along with people from different cultures. Besides, with a mixed background, my status gradually shifted from Taiwanese to international as well.&lt;/p&gt;
&lt;p&gt;Now I have the ability to build my community and accommodate wherever I am. Embracing the difference makes me visible, and the journey itself has the meaning. At the end of the day, we are all from Earth.&lt;/p&gt;
&lt;p&gt;I choose NFT as the medium because its inerasability aligns with the critical idea of existence in the project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improved Lite Audio-Visual Speech Enhancement (iLAVSE)</title>
      <link>https://kagaminccino.github.io/project/ilavse/</link>
      <pubDate>Sat, 19 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://kagaminccino.github.io/project/ilavse/</guid>
      <description>&lt;p&gt;Numerous studies have investigated the effectiveness of audio-visual multimodal learning for speech enhancement (AVSE) tasks, seeking a solution that uses visual data as auxiliary and complementary input to reduce the noise of noisy speech signals. Recently, we proposed a lite audio-visual speech enhancement (LAVSE) algorithm. Compared to conventional AVSE systems, LAVSE requires less online computation and moderately solves the user privacy problem on facial data. In this study, we extend LAVSE to improve its ability to address three practical issues often encountered in implementing AVSE systems, namely, the requirement for additional visual data, audio-visual asynchronization, and low-quality visual data. The proposed system is termed improved LAVSE (iLAVSE), which uses a convolutional recurrent neural network architecture as the core AVSE model. We evaluate iLAVSE on the Taiwan Mandarin speech with video dataset. Experimental results confirm that compared to conventional AVSE systems, iLAVSE can effectively overcome the aforementioned three practical issues and can improve enhancement performance. The results also confirm that iLAVSE is suitable for real-world scenarios, where high-quality audio-visual sensors may not always be available.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Taiwan Mandarin Speech with Video (TMSV)</title>
      <link>https://kagaminccino.github.io/project/tmsv/</link>
      <pubDate>Sun, 30 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://kagaminccino.github.io/project/tmsv/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://bio-asplab.citi.sinica.edu.tw/testsml.github.io/Opensource.html#TMSV&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TMSV (Taiwan Mandarin Speech with Video)&lt;/a&gt; is an audio-visual dataset based on the script of TMHINT (Taiwan Mandarin hearing in noise test). TMSV was recorded by 18 speakers, including 13 males and 5 females, each providing 320 video clips, amounting a total of 5,760 speech utterances. Each utterance in the TMHINT script consists of 10 Chinese characters. The length of each clip in TMSV is approximately 2â€“4 seconds. The video clips were recorded in a recording studio with sufficient light, and the speakers were filmed from the front view at 50 frames per second at a resolution of 1080p. The audio channels were recorded at 48 kHz. The misread labels and actual readed texts for ASR tasks are provided as well. The extracted wav files in the audio folders are downsampled to 16 kHz in mono channel.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lite Audio-Visual Speech Enhancement (LAVSE)</title>
      <link>https://kagaminccino.github.io/project/lavse/</link>
      <pubDate>Fri, 24 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://kagaminccino.github.io/project/lavse/</guid>
      <description>&lt;p&gt;Previous studies have confirmed the effectiveness of incorporating visual information into speech enhancement (SE) systems. Despite improved denoising performance, two problems may be encountered when implementing an audio-visual SE (AVSE) system: (1) additional processing costs are incurred to incorporate visual input and (2) the use of face or lip images may cause privacy problems. In this study, we propose a Lite AVSE (LAVSE) system to address these problems. The system includes two visual data compression techniques and removes the visual feature extraction network from the training model, yielding better online computation efficiency. Our experimental results indicate that the proposed LAVSE system can provide notably better performance than an audio-only SE system with a similar number of model parameters. In addition, the experimental results confirm the effectiveness of the two techniques for visual data compression.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Smooth and Flexible Movement Control of a Robot Arm</title>
      <link>https://kagaminccino.github.io/project/robotarm/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://kagaminccino.github.io/project/robotarm/</guid>
      <description>&lt;p&gt;We improved a nonlinear reference shaping controller for manipulators sharing their workspace with humans. The controller is based on the slow and rapid adaptations, which we tried to enhance. After the progress, the slow adaptation can generate movements with smooth endpoint velocity profiles when target position is changed. The rapid adaptation is upgraded as well with respect to not only significantly large external forces but also slight ones. They make the manipulators capable of behaving compliantly to the external forces, and also resuming the motion after the forces are removed, even when the shifts are small. Force detectors are unnecessary in this control system. The validity of the proposed ideas was confirmed via simulations on a planar 4-DOF manipulator.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Flyback Converter</title>
      <link>https://kagaminccino.github.io/project/flyback/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://kagaminccino.github.io/project/flyback/</guid>
      <description>&lt;p&gt;The project of the Power Electronics Laboratory, an elective course at the Department of Electrical Engineering, NTU. Practice of PCB designing and welding.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ME Robot Cup</title>
      <link>https://kagaminccino.github.io/project/pneumatic/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://kagaminccino.github.io/project/pneumatic/</guid>
      <description>&lt;p&gt;The ME Robot Cup is a traditional annual event at the Department of Mechanical Engineering, NTU. The whole department, faculty and students, all enjoy the event together. Usually the competitors are junior or senior students, and freshmen and sophomore are the audience. Every year around 20 teams participate the ME Robot Cup with one robot for each. A team usually consists of 4-5 people.&lt;/p&gt;
&lt;p&gt;The competition that year was to build a pneumatic car which could race over a specific race track with other teams. The race track includes obstacles like hills and some gates the robot needed to pass.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
